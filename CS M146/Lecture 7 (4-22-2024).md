**Decision Tree**
Given features, sequentially make decision leading you to final labels.

Greedy can be used to build the tree
*feature can have a real value but has to be given a range (threshold)*
choose by search to maximize informational gain
number of thresholds is hyperparameter

How far do you keep splitting?
- How do we choose hyperparameters

Cross-validation
- divide data into three categories: training, validation, and test data.
- Using training data, create a tree with particular choice of hyperparameter.
- validate the tree with validation data.
- use test data only after the final model is chosen.

**Inductive Bias**
close by points have same label
test points inherit the label of nearest neighbor in dataset
*Note: No explicit model developed from dataset*
