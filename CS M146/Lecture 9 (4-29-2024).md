# Kernel

**Positive definite kernel**
A positive (semi-)definite kernel $k: X \times X \rightarrow$ is such that $\forall x_i, i=1,...,N$ the matrix $K$, $(K)_{ij} = K(x_i,x_j), K \in \mathbb R^{N\times N}$ is positive semi definite.

K is p.s.d. if $\forall z, z^TKz \geq 0$.

**Mancer theorem**
a bivariate funciton $k(\cdot, \cdot)$ is a kernel function, if and only if, for any $N$ and any $x_1, x_2, ..., x_N$, the matrix K is positive semidefinite 

*a valid kernel is such that $\exists \phi (x) \text{ such that }  k(x,u) = <\phi(x), \phi(y)>$*

# Support Vector Machines (SVM)
- One of the most well used ML algorithm
- Most successful is the kernelized SVM

**Perceptron**
We want a hyperplane with max gap (max distance from the closest points)
Affine plane: plane that satisfies $w\cdot x +b=0$

Signed distance
$$d_{\mathcal H}(u) = \frac{w^Tu+b}{||w||}$$
For linearly separable spaces, $y_n \cdot d_{\mathcal H}(\phi (x)) = |d_{\mathcal H}(\phi (x))|$. (Since $y_n$ and $d_{\mathcal H}(\phi (x))$ have the same sign)

Optimization
$$\underset{w,b}{max} \{\underset{n}{min} \frac {y_n[w^T\phi(x_n)+b]}{||w||_2}\}$$
