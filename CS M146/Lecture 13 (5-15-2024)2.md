Recap:
- If error($\epsilon$) is small, the rate($\beta$) is big.
- decision stump single dimesion decision boundary

**Adaboost cont**
- For each iteration, the loss function is not the same since the weight is chagned.

Till now we had access to labeled datasets.
Unsupervised learning: no labeled datasets.

# Clustering
- given unlabeled data, we want to find the structure of the dataset.
Idea: Iterate between assignment & representative/center calculation

**K-means clustering**
Goal: Assign each point to a cluster with representative $\mu_k$. 
Clustering objective function (Cost function)
$$J(\{r_{nk}\}, \{\mu_k\}) = \sum^N_{n=1} \sum^K_{k=1} r_{nk} ||x_n-\mu_k||^2_2$$
$\mathcal C_k =\{x_n: x_n \text{is in } k^{th}  \text{ cluster}\}$  $C_k = \{n: x_n \in \mathcal C_k\}$
$r_{nk} = \begin{cases} 1 \text{ if } n\in C_k \\ 0 \text{  }else \end{cases}$ : assignment,   $\mu_k$: set of centers
We want to find the assignment and a set of centers so that the function J is minimized.

**K-means algorithm**
Assume the current value of $\mu$ is fixed, and minimize J over $r_{nk}$, which leads to the following cluster assignment rule
$$r_{nk} = \begin{cases} 1 \text{ if } k = argmin||x_n - \mu_j||^2_2 \\ 0 \text{ otherwise}\end{cases}$$
Assume the current value of $r_{nk}$ fixed, minimize J over $\mu_k$, which leads to update the prototypes of the clusters
$$\mu_k = \frac{\sum_n r_{nk}x_n}{\sum_n r_{nk}}$$
